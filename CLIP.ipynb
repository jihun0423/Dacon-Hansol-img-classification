{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNEZtHbq/RLOamNoqhoWlrl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihun0423/Dacon-Hansol-img-classification/blob/main/CLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "id": "9w2PCIh9wuol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "clip.available_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BocPgGdtwxpA",
        "outputId": "0f5cbe39-fafc-46ec-daae-b65c733724f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RN50',\n",
              " 'RN101',\n",
              " 'RN50x4',\n",
              " 'RN50x16',\n",
              " 'RN50x64',\n",
              " 'ViT-B/32',\n",
              " 'ViT-B/16',\n",
              " 'ViT-L/14',\n",
              " 'ViT-L/14@336px']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "81kKPfmfkYiG"
      },
      "outputs": [],
      "source": [
        "# !sudo apt-get install -y fonts-nanum\n",
        "# !sudo fc-cache -fv\n",
        "# !rm ~/.cache/matplotlib -rf\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from PIL import Image\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZM3Ru7dkdsB",
        "outputId": "71f49692-b227-4506-ee64-1702792c477e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y9P5_qLakdvG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-V9pMwPSkdx4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "pyQI07HWxVUJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YStFKe75xVW6",
        "outputId": "86ea3dc4-1cf4-40df-97e1-5a27e0ffa5d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CFG = {\n",
        "    'IMG_SIZE':224,\n",
        "    'EPOCHS': 10,\n",
        "    'LEARNING_RATE':3e-4,\n",
        "    'BATCH_SIZE':128,\n",
        "    'SEED': 41\n",
        "}"
      ],
      "metadata": {
        "id": "McMdG8XrxVZW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ],
      "metadata": {
        "id": "A3eynQr6xt0S"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/gdrive/MyDrive/open (2)/'\n",
        "train_folder = glob.glob(base_dir + 'train/*')\n",
        "train_img_list = glob.glob(base_dir + 'train/*/*')\n",
        "df = pd.DataFrame(columns=['img_path', 'label'])\n",
        "df['img_path'] = train_img_list\n",
        "df['label'] = df['img_path'].apply(lambda x : str(x).split('/')[-2])"
      ],
      "metadata": {
        "id": "u52K-CQMxVbo"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['label'])"
      ],
      "metadata": {
        "id": "XlVPr1NKzbUP"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plus_folder = glob.glob(base_dir + 'plus/*')\n",
        "\n",
        "plus_path = []\n",
        "for folder in plus_folder:\n",
        "    tmp = glob.glob(folder + '/*')\n",
        "    plus_path += tmp"
      ],
      "metadata": {
        "id": "9uqx8khotuvv"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plus_df = pd.DataFrame(plus_path, columns=['img_path'])\n",
        "plus_df['label'] = plus_df['img_path'].apply(lambda x: x.split('/')[-2])"
      ],
      "metadata": {
        "id": "ISbKuybNuqQe"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plus_df['label']=plus_df['label'].astype(int)"
      ],
      "metadata": {
        "id": "xRbWow4FwbP7"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df,plus_df])"
      ],
      "metadata": {
        "id": "INMiUTT6vGX3"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4pRU1YfwQ-S",
        "outputId": "19964706-9a03-4718-f27d-167b5d38311e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18    1405\n",
              "10     595\n",
              "1      307\n",
              "3      210\n",
              "15     162\n",
              "2      145\n",
              "11     142\n",
              "7      130\n",
              "6       99\n",
              "9       57\n",
              "5       54\n",
              "17      51\n",
              "14      27\n",
              "12      22\n",
              "13      17\n",
              "4       14\n",
              "0       12\n",
              "8       10\n",
              "16      10\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(0, '가구수정'),\n",
        " (1, '걸레받이수정'),\n",
        " (2, '곰팡이'),\n",
        " (3, '꼬임'),\n",
        " (4, '녹오염'),\n",
        " (5, '들뜸'),\n",
        " (6, '면불량'),\n",
        " (7, '몰딩수정'),\n",
        " (8, '반점'),\n",
        " (9, '석고수정'),\n",
        " (10, '오염'),\n",
        " (11, '오타공'),\n",
        " (12, '울음'),\n",
        " (13, '이음부불량'),\n",
        " (14, '창틀,문틀수정'),\n",
        " (15, '터짐'),\n",
        " (16, '틈새과다'),\n",
        " (17, '피스'),\n",
        " (18, '훼손')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLCGcYRWmeeo",
        "outputId": "1728fee2-88ee-4073-abfc-71747ad587ff"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '가구수정'),\n",
              " (1, '걸레받이수정'),\n",
              " (2, '곰팡이'),\n",
              " (3, '꼬임'),\n",
              " (4, '녹오염'),\n",
              " (5, '들뜸'),\n",
              " (6, '면불량'),\n",
              " (7, '몰딩수정'),\n",
              " (8, '반점'),\n",
              " (9, '석고수정'),\n",
              " (10, '오염'),\n",
              " (11, '오타공'),\n",
              " (12, '울음'),\n",
              " (13, '이음부불량'),\n",
              " (14, '창틀,문틀수정'),\n",
              " (15, '터짐'),\n",
              " (16, '틈새과다'),\n",
              " (17, '피스'),\n",
              " (18, '훼손')]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['label'] == 0, 'text'] =  'the crack with drawer and wall'\n",
        "df.loc[df['label'] == 1, 'text'] =  'the baseboard with a crack'\n",
        "df.loc[df['label'] == 2, 'text'] =  'stains on the wall'\n",
        "df.loc[df['label'] == 3, 'text'] =  'seam wrinkles around the corner'\n",
        "df.loc[df['label'] == 4, 'text'] =  'wall with a brown spot'\n",
        "df.loc[df['label'] == 5, 'text'] =  'wall paper is coming off at the corner'\n",
        "df.loc[df['label'] == 6, 'text'] =  'a protruding part of the wallpaper'\n",
        "df.loc[df['label'] == 7, 'text'] =  'corner of the ceiling'\n",
        "df.loc[df['label'] == 8, 'text'] =  'red dots or blue dots on the wall'\n",
        "df.loc[df['label'] == 9, 'text'] =  'crack on the plaster board'\n",
        "df.loc[df['label'] == 10, 'text'] = 'contamination on the wall'\n",
        "df.loc[df['label'] == 11, 'text'] = 'a hole at the ceiling'\n",
        "df.loc[df['label'] == 12, 'text'] = 'wrinkle on the ceiling or wall'\n",
        "df.loc[df['label'] == 13, 'text'] = 'wall paper is cut'\n",
        "df.loc[df['label'] == 14, 'text'] = 'the door frame with a crack'\n",
        "df.loc[df['label'] == 15, 'text'] = 'crack near electric outlet'\n",
        "df.loc[df['label'] == 16, 'text'] = 'serious crack at the corner'\n",
        "df.loc[df['label'] == 17, 'text'] = 'nail on the wall'\n",
        "df.loc[df['label'] == 18, 'text'] = 'a hole or crack in the wallpaper'"
      ],
      "metadata": {
        "id": "gu0KpD-dneFb"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FU6qLLbivipV",
        "outputId": "3d125511-8742-49eb-f7a4-e0ebb6e09296"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             img_path  label  \\\n",
              "0   /content/gdrive/MyDrive/open (2)/train/가구수ᄌ...      0   \n",
              "1   /content/gdrive/MyDrive/open (2)/train/가구수ᄌ...      0   \n",
              "2   /content/gdrive/MyDrive/open (2)/train/가구수ᄌ...      0   \n",
              "3   /content/gdrive/MyDrive/open (2)/train/가구수ᄌ...      0   \n",
              "4   /content/gdrive/MyDrive/open (2)/train/가구수ᄌ...      0   \n",
              "..                                                ...    ...   \n",
              "7   /content/gdrive/MyDrive/open (2)/plus/16/틈새...     16   \n",
              "8   /content/gdrive/MyDrive/open (2)/plus/16/틈새...     16   \n",
              "9   /content/gdrive/MyDrive/open (2)/plus/16/틈새...     16   \n",
              "10  /content/gdrive/MyDrive/open (2)/plus/16/틈새...     16   \n",
              "11  /content/gdrive/MyDrive/open (2)/plus/16/틈새...     16   \n",
              "\n",
              "                              text  \n",
              "0   the crack with drawer and wall  \n",
              "1   the crack with drawer and wall  \n",
              "2   the crack with drawer and wall  \n",
              "3   the crack with drawer and wall  \n",
              "4   the crack with drawer and wall  \n",
              "..                             ...  \n",
              "7      serious crack at the corner  \n",
              "8      serious crack at the corner  \n",
              "9      serious crack at the corner  \n",
              "10     serious crack at the corner  \n",
              "11     serious crack at the corner  \n",
              "\n",
              "[3469 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83a351dd-1aff-4fef-aa64-5c7209a84eeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_path</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/train/가구수ᄌ...</td>\n",
              "      <td>0</td>\n",
              "      <td>the crack with drawer and wall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/train/가구수ᄌ...</td>\n",
              "      <td>0</td>\n",
              "      <td>the crack with drawer and wall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/train/가구수ᄌ...</td>\n",
              "      <td>0</td>\n",
              "      <td>the crack with drawer and wall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/train/가구수ᄌ...</td>\n",
              "      <td>0</td>\n",
              "      <td>the crack with drawer and wall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/train/가구수ᄌ...</td>\n",
              "      <td>0</td>\n",
              "      <td>the crack with drawer and wall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/plus/16/틈새...</td>\n",
              "      <td>16</td>\n",
              "      <td>serious crack at the corner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/plus/16/틈새...</td>\n",
              "      <td>16</td>\n",
              "      <td>serious crack at the corner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/plus/16/틈새...</td>\n",
              "      <td>16</td>\n",
              "      <td>serious crack at the corner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/plus/16/틈새...</td>\n",
              "      <td>16</td>\n",
              "      <td>serious crack at the corner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/plus/16/틈새...</td>\n",
              "      <td>16</td>\n",
              "      <td>serious crack at the corner</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3469 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83a351dd-1aff-4fef-aa64-5c7209a84eeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83a351dd-1aff-4fef-aa64-5c7209a84eeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83a351dd-1aff-4fef-aa64-5c7209a84eeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df, df['label'], test_size=0.33, random_state=777, stratify=df['label'])"
      ],
      "metadata": {
        "id": "RVUQUtaPvv74"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class FlawDataset(Dataset):\n",
        "    def __init__(self, csv_df, transform):\n",
        "        self.csv_df = csv_df\n",
        "        self.img_list = []\n",
        "        self.transform =transform\n",
        "        for img_path in self.csv_df['img_path']:\n",
        "            self.img_list.append(Image.open(img_path))\n",
        "        \n",
        "        \n",
        "        self.text = self.csv_df['text'].to_list()\n",
        "        self.label = self.csv_df['label'].to_list()\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_list[idx]\n",
        "        text = self.text[idx]\n",
        "        label = self.label[idx]\n",
        "        \n",
        "        img = self.transform(img)\n",
        "        \n",
        "        return img, text, label"
      ],
      "metadata": {
        "id": "SZJ0F04Gvv-U"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, BatchSampler\n",
        "class BalancedBatchSampler(BatchSampler):\n",
        "    \"\"\"\n",
        "    BatchSampler - from a MNIST-like dataset, samples n_classes and within these classes samples n_samples.\n",
        "    Returns batches of size n_classes * n_samples\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, labels, n_classes, n_samples):\n",
        "        self.labels = labels\n",
        "        self.labels_set = list(set(self.labels.numpy()))\n",
        "        self.label_to_indices = {label: np.where(self.labels.numpy() == label)[0]\n",
        "                                 for label in self.labels_set}\n",
        "        for l in self.labels_set:\n",
        "            np.random.shuffle(self.label_to_indices[l])\n",
        "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
        "        self.count = 0\n",
        "        self.n_classes = n_classes\n",
        "        self.n_samples = n_samples\n",
        "        self.n_dataset = len(self.labels)\n",
        "        self.batch_size = self.n_samples * self.n_classes\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.count = 0\n",
        "        while self.count + self.batch_size < self.n_dataset:\n",
        "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
        "            indices = []\n",
        "            for class_ in classes:\n",
        "                indices.extend(self.label_to_indices[class_][\n",
        "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
        "                                                                         class_] + self.n_samples])\n",
        "                self.used_label_indices_count[class_] += self.n_samples\n",
        "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
        "                    np.random.shuffle(self.label_to_indices[class_])\n",
        "                    self.used_label_indices_count[class_] = 0\n",
        "            yield indices\n",
        "            self.count += self.n_classes * self.n_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_dataset // self.batch_size"
      ],
      "metadata": {
        "id": "Kr-MU2MKvwA3"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, preprocess = clip.load('ViT-L/14@336px', device=device, jit=False)"
      ],
      "metadata": {
        "id": "1NwJsnpZwU1b"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM75hFCuwU3v",
        "outputId": "be6998f7-56e5-487a-b506-4dde65833838"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    Resize(size=336, interpolation=bicubic, max_size=None, antialias=warn)\n",
              "    CenterCrop(size=(336, 336))\n",
              "    <function _convert_image_to_rgb at 0x7f4d9d9a6290>\n",
              "    ToTensor()\n",
              "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "train_preprocess = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomResizedCrop(size=(336, 336), interpolation=InterpolationMode.BICUBIC, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
        "    transforms.autoaugment.TrivialAugmentWide(interpolation=InterpolationMode.BILINEAR),\n",
        "    #_convert_image_to_rgb,\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ConvertImageDtype(torch.float),\n",
        "    transforms.Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711)),\n",
        "    transforms.RandomErasing(p=0.1)\n",
        "]\n",
        ")\n",
        "\n",
        "val_preprocess = transforms.Compose([\n",
        "     transforms.ToPILImage(),\n",
        "    transforms.Resize(size=(336, 336), interpolation=InterpolationMode.BICUBIC, max_size=None, antialias=None),\n",
        "    transforms.CenterCrop(size=(336, 336)),\n",
        "    #_convert_image_to_rgb,\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ConvertImageDtype(torch.float),\n",
        "    transforms.Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711)),\n",
        "]\n",
        ")"
      ],
      "metadata": {
        "id": "1Y1BZm-oxErF"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process = transforms.Compose([\n",
        "    transforms.Resize(size=336, interpolation=InterpolationMode.BICUBIC, max_size=None, antialias=None),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "y_EB54ixxEt0"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_path_list, label, text, transforms=None):\n",
        "        self.img_path_list = img_path_list\n",
        "        self.label = label\n",
        "        self.transforms = transforms\n",
        "        self.text = text\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_path_list[index]\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
        "        \n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "        \n",
        "        if self.label is not None:\n",
        "            label = self.label[index]\n",
        "            text = self.text[index]\n",
        "            return image, text, label\n",
        "        else:\n",
        "            return image\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_path_list)"
      ],
      "metadata": {
        "id": "btA9j8VS0wMo"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(x_train['img_path'].values, x_train['label'].values, x_train['text'].values,train_preprocess)\n",
        "test_dataset = CustomDataset(x_test['img_path'].values, x_test['label'].values, x_test['text'].values,val_preprocess)"
      ],
      "metadata": {
        "id": "61anjiPQ1fTk"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 19"
      ],
      "metadata": {
        "id": "XhlYMTqCxEzD"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = torch.tensor([item[2] for item in train_dataset])\n",
        "train_sampler = BalancedBatchSampler(train_labels, BATCH_SIZE, 1)\n",
        "train_dataloader = DataLoader(train_dataset, batch_sampler=train_sampler, num_workers=8,pin_memory=True)\n",
        "\n",
        "test_labels = torch.tensor([item[2] for item in test_dataset])\n",
        "test_sampler = BalancedBatchSampler(test_labels, BATCH_SIZE, 1)\n",
        "test_dataloader = DataLoader(test_dataset, batch_sampler=test_sampler, num_workers=8,pin_memory=True)"
      ],
      "metadata": {
        "id": "kFxHlKUZxE1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Dg0AcdLxE37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH = 40"
      ],
      "metadata": {
        "id": "KSVsqmhkxE6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_models_to_fp32(model): \n",
        "    for p in model.parameters(): \n",
        "        p.data = p.data.float() \n",
        "        p.grad.data = p.grad.data.float() \n",
        "\n",
        "if device == \"cpu\":\n",
        "    model.float()\n",
        "\n",
        "loss_img = nn.CrossEntropyLoss()\n",
        "loss_txt = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(model.parameters(), lr=1e-6,betas=(0.9,0.98),eps=1e-6,weight_decay=0.05)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=1e-5, momentum=0.9, weight_decay = 1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_dataloader)*EPOCH)"
      ],
      "metadata": {
        "id": "rHJzKZCMvwIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_f1 = 1e-5\n",
        "best_ep = -1\n",
        "ans = x_test['label_index'].to_list()\n",
        "best_te_loss = 1e5\n",
        "f1_ls = []\n",
        "\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    print(f\"running epoch {epoch}, best test loss {best_te_loss} after epoch {best_ep}\")\n",
        "    step = 0\n",
        "    tr_loss = 0\n",
        "    model.train()\n",
        "    pbar = tqdm(train_dataloader, leave=False)\n",
        "    for batch in pbar:\n",
        "        step += 1\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        images, texts, _ = batch\n",
        "        images = images.to(device)\n",
        "        texts = clip.tokenize(texts).to(device)\n",
        "        #print(images.shape, texts.shape)\n",
        "        logits_per_image, logits_per_text = model(images, texts)\n",
        "        ground_truth = torch.arange(BATCH_SIZE).to(device)\n",
        "\n",
        "        total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
        "        total_loss.backward()\n",
        "        tr_loss += total_loss.item()\n",
        "        if device == \"cpu\":\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        else:\n",
        "            convert_models_to_fp32(model)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            clip.model.convert_weights(model)\n",
        "        pbar.set_description(f\"train batchCE: {total_loss.item()}\", refresh=True)\n",
        "    tr_loss /= step\n",
        "    \n",
        "    step = 0\n",
        "    te_loss = 0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        test_pbar = tqdm(test_dataloader, leave=False)\n",
        "        for batch in test_pbar:\n",
        "            step += 1\n",
        "            images, texts, _ = batch\n",
        "            images = images.to(device)\n",
        "            texts = clip.tokenize(texts).to(device)\n",
        "            logits_per_image, logits_per_text = model(images, texts)\n",
        "            ground_truth = torch.arange(BATCH_SIZE).to(device)\n",
        "\n",
        "            total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
        "            te_loss += total_loss.item()\n",
        "            test_pbar.set_description(f\"test batchCE: {total_loss.item()}\", refresh=True)\n",
        "        te_loss /= step\n",
        "        \n",
        "    preds = []\n",
        "    for image in x_test['image']:\n",
        "        image = preprocess(Image.open(image)).unsqueeze(0).to(device)\n",
        "        text = clip.tokenize(text_label).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            image_features = model.encode_image(image)\n",
        "            text_features = model.encode_text(text)\n",
        "\n",
        "            logits_per_image, logits_per_text = model(image, text)\n",
        "            probs = logits_per_image.softmax(dim=-1).cpu()\n",
        "            prob_idx = probs.argmax()\n",
        "            preds.append(prob_idx)\n",
        "            \n",
        "            \n",
        "    ans = x_test['label_index'].to_list()\n",
        "    print(metrics.accuracy_score(ans, preds))\n",
        "    f1_acc = metrics.f1_score(ans, preds, average = 'macro')\n",
        "    print(f1_acc)\n",
        "    f1_ls.append(f1_acc)\n",
        "            \n",
        "            \n",
        "\n",
        "    if best_f1 < f1_acc:\n",
        "        best_f1_acc = f1_acc\n",
        "        best_ep = epoch\n",
        "        torch.save(model.state_dict(), \"./best_model_change_val336gpuno2f.pt\")\n",
        "        \n",
        "    print(f\"epoch {epoch}, tr_loss {tr_loss}, te_loss {te_loss}\")\n",
        "torch.save(model.state_dict(), \"./lasttr224_model25.pt\")"
      ],
      "metadata": {
        "id": "h194zylLvwK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vjK9N0WIzoTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "89y3MytczoVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gjswQKJkzoYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "['the door frame with a crack' : 'bad joint',\n",
        " 'the baseboard with a crack' : 'mopholder',\n",
        " 'wall paper is coming off at the corner' : 'crack',\n",
        " 'the crack with drawer and wall' : 'Furniture',\n",
        " 'corner of the ceiling' : 'molding',\n",
        " 'crack near electric outlet' : 'window frame',\n",
        " 'serious crack at the corner' : 'gap',\n",
        " 'a hole at the ceiling' : 'black spot',\n",
        " 'wall paper is cut' : 'wailing',\n",
        " 'crack on the ceiling' : 'plaster',\n",
        " 'stains on the wall' : 'mold',\n",
        " 'red dots or blue dots on the wall' : 'half spot',\n",
        " 'a protruding part of the wallpaper' : 'cotton defect',\n",
        " 'wrinkle on the ceiling or wall' : 'wrinkle',\n",
        " 'seam wrinkles around the corner' : 'twist',\n",
        " 'wall with a brown spot' : 'rust pollution',\n",
        " 'nail on the wall':'piece' ,\n",
        " 'contamination on the wall' : 'contamination',\n",
        " 'a hole or crack in the wallpaper' :  'damage']"
      ],
      "metadata": {
        "id": "zENAd1v0lQ37"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}