{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMy8pYZXqAGuTWRBQ10BtqF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihun0423/Dacon-Hansol-img-classification/blob/main/CLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "id": "9w2PCIh9wuol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "clip.available_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BocPgGdtwxpA",
        "outputId": "0f5cbe39-fafc-46ec-daae-b65c733724f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RN50',\n",
              " 'RN101',\n",
              " 'RN50x4',\n",
              " 'RN50x16',\n",
              " 'RN50x64',\n",
              " 'ViT-B/32',\n",
              " 'ViT-B/16',\n",
              " 'ViT-L/14',\n",
              " 'ViT-L/14@336px']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81kKPfmfkYiG"
      },
      "outputs": [],
      "source": [
        "# !sudo apt-get install -y fonts-nanum\n",
        "# !sudo fc-cache -fv\n",
        "# !rm ~/.cache/matplotlib -rf\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from PIL import Image\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZM3Ru7dkdsB",
        "outputId": "71f49692-b227-4506-ee64-1702792c477e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y9P5_qLakdvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-V9pMwPSkdx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "pyQI07HWxVUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YStFKe75xVW6",
        "outputId": "86ea3dc4-1cf4-40df-97e1-5a27e0ffa5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CFG = {\n",
        "    'IMG_SIZE':224,\n",
        "    'EPOCHS': 10,\n",
        "    'LEARNING_RATE':3e-4,\n",
        "    'BATCH_SIZE':128,\n",
        "    'SEED': 41\n",
        "}"
      ],
      "metadata": {
        "id": "McMdG8XrxVZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ],
      "metadata": {
        "id": "A3eynQr6xt0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/gdrive/MyDrive/open (2)/'\n",
        "train_folder = glob.glob(base_dir + 'train/*')\n",
        "train_img_list = glob.glob(base_dir + 'train/*/*')\n",
        "df = pd.DataFrame(columns=['img_path', 'label'])\n",
        "df['img_path'] = train_img_list\n",
        "df['label'] = df['img_path'].apply(lambda x : str(x).split('/')[-2])"
      ],
      "metadata": {
        "id": "u52K-CQMxVbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['label'])"
      ],
      "metadata": {
        "id": "XlVPr1NKzbUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plus_folder = glob.glob(base_dir + 'plus/*')\n",
        "\n",
        "plus_path = []\n",
        "for folder in plus_folder:\n",
        "    tmp = glob.glob(folder + '/*')\n",
        "    plus_path += tmp"
      ],
      "metadata": {
        "id": "9uqx8khotuvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plus_df = pd.DataFrame(plus_path, columns=['img_path'])\n",
        "plus_df['label'] = plus_df['img_path'].apply(lambda x: x.split('/')[-2])"
      ],
      "metadata": {
        "id": "ISbKuybNuqQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plus_df['label']=plus_df['label'].astype(int)"
      ],
      "metadata": {
        "id": "xRbWow4FwbP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df,plus_df])"
      ],
      "metadata": {
        "id": "INMiUTT6vGX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4pRU1YfwQ-S",
        "outputId": "19964706-9a03-4718-f27d-167b5d38311e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18    1405\n",
              "10     595\n",
              "1      307\n",
              "3      210\n",
              "15     162\n",
              "2      145\n",
              "11     142\n",
              "7      130\n",
              "6       99\n",
              "9       57\n",
              "5       54\n",
              "17      51\n",
              "14      27\n",
              "12      22\n",
              "13      17\n",
              "4       14\n",
              "0       12\n",
              "8       10\n",
              "16      10\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(0, '가구수정'),\n",
        " (1, '걸레받이수정'),\n",
        " (2, '곰팡이'),\n",
        " (3, '꼬임'),\n",
        " (4, '녹오염'),\n",
        " (5, '들뜸'),\n",
        " (6, '면불량'),\n",
        " (7, '몰딩수정'),\n",
        " (8, '반점'),\n",
        " (9, '석고수정'),\n",
        " (10, '오염'),\n",
        " (11, '오타공'),\n",
        " (12, '울음'),\n",
        " (13, '이음부불량'),\n",
        " (14, '창틀,문틀수정'),\n",
        " (15, '터짐'),\n",
        " (16, '틈새과다'),\n",
        " (17, '피스'),\n",
        " (18, '훼손')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLCGcYRWmeeo",
        "outputId": "1728fee2-88ee-4073-abfc-71747ad587ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '가구수정'),\n",
              " (1, '걸레받이수정'),\n",
              " (2, '곰팡이'),\n",
              " (3, '꼬임'),\n",
              " (4, '녹오염'),\n",
              " (5, '들뜸'),\n",
              " (6, '면불량'),\n",
              " (7, '몰딩수정'),\n",
              " (8, '반점'),\n",
              " (9, '석고수정'),\n",
              " (10, '오염'),\n",
              " (11, '오타공'),\n",
              " (12, '울음'),\n",
              " (13, '이음부불량'),\n",
              " (14, '창틀,문틀수정'),\n",
              " (15, '터짐'),\n",
              " (16, '틈새과다'),\n",
              " (17, '피스'),\n",
              " (18, '훼손')]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['label'] == 0, 'text'] =  'the crack with drawer and wall'\n",
        "df.loc[df['label'] == 1, 'text'] =  'the baseboard with a crack'\n",
        "df.loc[df['label'] == 2, 'text'] =  'stains on the wall'\n",
        "df.loc[df['label'] == 3, 'text'] =  'seam wrinkles around the corner'\n",
        "df.loc[df['label'] == 4, 'text'] =  'wall with a brown spot'\n",
        "df.loc[df['label'] == 5, 'text'] =  'wall paper is coming off at the corner'\n",
        "df.loc[df['label'] == 6, 'text'] =  'a protruding part of the wallpaper'\n",
        "df.loc[df['label'] == 7, 'text'] =  'corner of the ceiling'\n",
        "df.loc[df['label'] == 8, 'text'] =  'red dots or blue dots on the wall'\n",
        "#df.loc[df['label'] == 9, 'text'] =  'crack on the plaster board'\n",
        "df.loc[df['label'] == 9, 'text'] =  'crack on the ceiling'\n",
        "df.loc[df['label'] == 10, 'text'] = 'contamination on the wall'\n",
        "df.loc[df['label'] == 11, 'text'] = 'a hole at the ceiling'\n",
        "df.loc[df['label'] == 12, 'text'] = 'wrinkle on the ceiling or wall'\n",
        "df.loc[df['label'] == 13, 'text'] = 'wall paper is cut'\n",
        "df.loc[df['label'] == 14, 'text'] = 'the door frame with a crack'\n",
        "df.loc[df['label'] == 15, 'text'] = 'crack near electric outlet'\n",
        "df.loc[df['label'] == 16, 'text'] = 'serious crack at the corner'\n",
        "df.loc[df['label'] == 17, 'text'] = 'nail on the wall'\n",
        "df.loc[df['label'] == 18, 'text'] = 'a hole or crack in the wallpaper'"
      ],
      "metadata": {
        "id": "gu0KpD-dneFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "['the door frame with a crack' : 'bad joint',\n",
        " 'the baseboard with a crack' : 'mopholder',\n",
        " 'wall paper is coming off at the corner' : 'crack',\n",
        " 'the crack with drawer and wall' : 'Furniture',\n",
        " 'corner of the ceiling' : 'molding',\n",
        " 'crack near electric outlet' : 'window frame',\n",
        " 'serious crack at the corner' : 'gap',\n",
        " 'a hole at the ceiling' : 'black spot',\n",
        " 'wall paper is cut' : 'wailing',\n",
        " 'crack on the ceiling' : 'plaster',\n",
        " 'stains on the wall' : 'mold',\n",
        " 'red dots or blue dots on the wall' : 'half spot',\n",
        " 'a protruding part of the wallpaper' : 'cotton defect',\n",
        " 'wrinkle on the ceiling or wall' : 'wrinkle',\n",
        " 'seam wrinkles around the corner' : 'twist',\n",
        " 'wall with a brown spot' : 'rust pollution',\n",
        " 'nail on the wall':'piece' ,\n",
        " 'contamination on the wall' : 'contamination',\n",
        " 'a hole or crack in the wallpaper' :  'damage']"
      ],
      "metadata": {
        "id": "BPuFOQP6D10D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FU6qLLbivipV",
        "outputId": "3d125511-8742-49eb-f7a4-e0ebb6e09296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             img_path  label  \\\n",
              "0   /content/gdrive/MyDrive/open (2)/train/가구수ᄌ...      0   \n",
              "1   /content/gdrive/MyDrive/open (2)/train/가구수ᄌ...      0   \n",
              "2   /content/gdrive/MyDrive/open (2)/train/가구수ᄌ...      0   \n",
              "3   /content/gdrive/MyDrive/open (2)/train/가구수ᄌ...      0   \n",
              "4   /content/gdrive/MyDrive/open (2)/train/가구수ᄌ...      0   \n",
              "..                                                ...    ...   \n",
              "7   /content/gdrive/MyDrive/open (2)/plus/16/틈새...     16   \n",
              "8   /content/gdrive/MyDrive/open (2)/plus/16/틈새...     16   \n",
              "9   /content/gdrive/MyDrive/open (2)/plus/16/틈새...     16   \n",
              "10  /content/gdrive/MyDrive/open (2)/plus/16/틈새...     16   \n",
              "11  /content/gdrive/MyDrive/open (2)/plus/16/틈새...     16   \n",
              "\n",
              "                              text  \n",
              "0   the crack with drawer and wall  \n",
              "1   the crack with drawer and wall  \n",
              "2   the crack with drawer and wall  \n",
              "3   the crack with drawer and wall  \n",
              "4   the crack with drawer and wall  \n",
              "..                             ...  \n",
              "7      serious crack at the corner  \n",
              "8      serious crack at the corner  \n",
              "9      serious crack at the corner  \n",
              "10     serious crack at the corner  \n",
              "11     serious crack at the corner  \n",
              "\n",
              "[3469 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83a351dd-1aff-4fef-aa64-5c7209a84eeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_path</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/train/가구수ᄌ...</td>\n",
              "      <td>0</td>\n",
              "      <td>the crack with drawer and wall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/train/가구수ᄌ...</td>\n",
              "      <td>0</td>\n",
              "      <td>the crack with drawer and wall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/train/가구수ᄌ...</td>\n",
              "      <td>0</td>\n",
              "      <td>the crack with drawer and wall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/train/가구수ᄌ...</td>\n",
              "      <td>0</td>\n",
              "      <td>the crack with drawer and wall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/train/가구수ᄌ...</td>\n",
              "      <td>0</td>\n",
              "      <td>the crack with drawer and wall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/plus/16/틈새...</td>\n",
              "      <td>16</td>\n",
              "      <td>serious crack at the corner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/plus/16/틈새...</td>\n",
              "      <td>16</td>\n",
              "      <td>serious crack at the corner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/plus/16/틈새...</td>\n",
              "      <td>16</td>\n",
              "      <td>serious crack at the corner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/plus/16/틈새...</td>\n",
              "      <td>16</td>\n",
              "      <td>serious crack at the corner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>/content/gdrive/MyDrive/open (2)/plus/16/틈새...</td>\n",
              "      <td>16</td>\n",
              "      <td>serious crack at the corner</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3469 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83a351dd-1aff-4fef-aa64-5c7209a84eeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83a351dd-1aff-4fef-aa64-5c7209a84eeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83a351dd-1aff-4fef-aa64-5c7209a84eeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_label = list(df.text.unique())"
      ],
      "metadata": {
        "id": "CtSVnPOb_lV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_2LXP_-_lYc",
        "outputId": "0967bf56-5dab-4ec1-85ce-6160fe99880b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the crack with drawer and wall',\n",
              " 'the baseboard with a crack',\n",
              " 'seam wrinkles around the corner',\n",
              " 'stains on the wall',\n",
              " 'wall with a brown spot',\n",
              " 'wall paper is coming off at the corner',\n",
              " 'corner of the ceiling',\n",
              " 'a protruding part of the wallpaper',\n",
              " 'red dots or blue dots on the wall',\n",
              " 'crack on the plaster board',\n",
              " 'a hole at the ceiling',\n",
              " 'contamination on the wall',\n",
              " 'wrinkle on the ceiling or wall',\n",
              " 'crack near electric outlet',\n",
              " 'nail on the wall',\n",
              " 'wall paper is cut',\n",
              " 'a hole or crack in the wallpaper',\n",
              " 'the door frame with a crack',\n",
              " 'serious crack at the corner']"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W1wur0K3_la4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df, df['label'], test_size=0.33, random_state=777, stratify=df['label'])"
      ],
      "metadata": {
        "id": "RVUQUtaPvv74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class FlawDataset(Dataset):\n",
        "    def __init__(self, csv_df, transform):\n",
        "        self.csv_df = csv_df\n",
        "        self.img_list = []\n",
        "        self.transform =transform\n",
        "        for img_path in self.csv_df['img_path']:\n",
        "            self.img_list.append(Image.open(img_path))\n",
        "        \n",
        "        \n",
        "        self.text = self.csv_df['text'].to_list()\n",
        "        self.label = self.csv_df['label'].to_list()\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_list[idx]\n",
        "        text = self.text[idx]\n",
        "        label = self.label[idx]\n",
        "        \n",
        "        img = self.transform(img)\n",
        "        \n",
        "        return img, text, label"
      ],
      "metadata": {
        "id": "SZJ0F04Gvv-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, BatchSampler\n",
        "class BalancedBatchSampler(BatchSampler):\n",
        "    \"\"\"\n",
        "    BatchSampler - from a MNIST-like dataset, samples n_classes and within these classes samples n_samples.\n",
        "    Returns batches of size n_classes * n_samples\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, labels, n_classes, n_samples):\n",
        "        self.labels = labels\n",
        "        self.labels_set = list(set(self.labels.numpy()))\n",
        "        self.label_to_indices = {label: np.where(self.labels.numpy() == label)[0]\n",
        "                                 for label in self.labels_set}\n",
        "        for l in self.labels_set:\n",
        "            np.random.shuffle(self.label_to_indices[l])\n",
        "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
        "        self.count = 0\n",
        "        self.n_classes = n_classes\n",
        "        self.n_samples = n_samples\n",
        "        self.n_dataset = len(self.labels)\n",
        "        self.batch_size = self.n_samples * self.n_classes\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.count = 0\n",
        "        while self.count + self.batch_size < self.n_dataset:\n",
        "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
        "            indices = []\n",
        "            for class_ in classes:\n",
        "                indices.extend(self.label_to_indices[class_][\n",
        "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
        "                                                                         class_] + self.n_samples])\n",
        "                self.used_label_indices_count[class_] += self.n_samples\n",
        "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
        "                    np.random.shuffle(self.label_to_indices[class_])\n",
        "                    self.used_label_indices_count[class_] = 0\n",
        "            yield indices\n",
        "            self.count += self.n_classes * self.n_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_dataset // self.batch_size"
      ],
      "metadata": {
        "id": "Kr-MU2MKvwA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, preprocess = clip.load('ViT-L/14@336px', device=device, jit=False)"
      ],
      "metadata": {
        "id": "1NwJsnpZwU1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM75hFCuwU3v",
        "outputId": "be6998f7-56e5-487a-b506-4dde65833838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    Resize(size=336, interpolation=bicubic, max_size=None, antialias=warn)\n",
              "    CenterCrop(size=(336, 336))\n",
              "    <function _convert_image_to_rgb at 0x7f4d9d9a6290>\n",
              "    ToTensor()\n",
              "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "train_preprocess = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomResizedCrop(size=(336, 336), interpolation=InterpolationMode.BICUBIC, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
        "    transforms.autoaugment.TrivialAugmentWide(interpolation=InterpolationMode.BILINEAR),\n",
        "    #_convert_image_to_rgb,\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ConvertImageDtype(torch.float),\n",
        "    transforms.Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711)),\n",
        "    transforms.RandomErasing(p=0.1)\n",
        "]\n",
        ")\n",
        "\n",
        "val_preprocess = transforms.Compose([\n",
        "     transforms.ToPILImage(),\n",
        "    transforms.Resize(size=(336, 336), interpolation=InterpolationMode.BICUBIC, max_size=None, antialias=None),\n",
        "    transforms.CenterCrop(size=(336, 336)),\n",
        "    #_convert_image_to_rgb,\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ConvertImageDtype(torch.float),\n",
        "    transforms.Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711)),\n",
        "]\n",
        ")"
      ],
      "metadata": {
        "id": "1Y1BZm-oxErF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process = transforms.Compose([\n",
        "    transforms.Resize(size=336, interpolation=InterpolationMode.BICUBIC, max_size=None, antialias=None),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "y_EB54ixxEt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_path_list, label, text, transforms=None):\n",
        "        self.img_path_list = img_path_list\n",
        "        self.label = label\n",
        "        self.transforms = transforms\n",
        "        self.text = text\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_path_list[index]\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
        "        \n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "        \n",
        "        if self.label is not None:\n",
        "            label = self.label[index]\n",
        "            text = self.text[index]\n",
        "            return image, text, label\n",
        "        else:\n",
        "            return image\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_path_list)"
      ],
      "metadata": {
        "id": "btA9j8VS0wMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(x_train['img_path'].values, x_train['label'].values, x_train['text'].values,train_preprocess)\n",
        "test_dataset = CustomDataset(x_test['img_path'].values, x_test['label'].values, x_test['text'].values,val_preprocess)"
      ],
      "metadata": {
        "id": "61anjiPQ1fTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(x_train['label'].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWXQuX-7--x_",
        "outputId": "d005e16b-72c5-4538-b598-192d3fc18015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 18, 18,  ...,  2, 18, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 19\n",
        "train_labels = torch.tensor([item[2] for item in train_dataset])\n",
        "# train_labels = torch.tensor(x_train['label'].values)\n",
        "train_sampler = BalancedBatchSampler(train_labels, BATCH_SIZE, 1)\n",
        "train_dataloader = DataLoader(train_dataset, batch_sampler=train_sampler, num_workers=8,pin_memory=True)\n",
        "\n",
        "test_labels = torch.tensor([item[2] for item in test_dataset])\n",
        "# test_labels = torch.tensor(x_test['label'].values)\n",
        "test_sampler = BalancedBatchSampler(test_labels, BATCH_SIZE, 1)\n",
        "test_dataloader = DataLoader(test_dataset, batch_sampler=test_sampler, num_workers=8,pin_memory=True)"
      ],
      "metadata": {
        "id": "kFxHlKUZxE1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Dg0AcdLxE37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH = 40"
      ],
      "metadata": {
        "id": "KSVsqmhkxE6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_models_to_fp32(model): \n",
        "    for p in model.parameters(): \n",
        "        p.data = p.data.float() \n",
        "        p.grad.data = p.grad.data.float() \n",
        "\n",
        "if device == \"cpu\":\n",
        "    model.float()\n",
        "\n",
        "loss_img = nn.CrossEntropyLoss()\n",
        "loss_txt = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(model.parameters(), lr=1e-6,betas=(0.9,0.98),eps=1e-6,weight_decay=0.05)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=1e-5, momentum=0.9, weight_decay = 1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_dataloader)*EPOCH)"
      ],
      "metadata": {
        "id": "rHJzKZCMvwIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_f1 = 1e-5\n",
        "best_ep = -1\n",
        "ans = x_test['label'].to_list()\n",
        "best_te_loss = 1e5\n",
        "f1_ls = []\n",
        "\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    print(f\"running epoch {epoch}, best test loss {best_te_loss} after epoch {best_ep}\")\n",
        "    step = 0\n",
        "    tr_loss = 0\n",
        "    model.train()\n",
        "    pbar = tqdm(train_dataloader, leave=False)\n",
        "    for batch in pbar:\n",
        "        step += 1\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        images, texts, _ = batch\n",
        "        images = images.to(device)\n",
        "        texts = clip.tokenize(texts).to(device)\n",
        "        #print(images.shape, texts.shape)\n",
        "        logits_per_image, logits_per_text = model(images, texts)\n",
        "        ground_truth = torch.arange(BATCH_SIZE).to(device)\n",
        "\n",
        "        total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
        "        total_loss.backward()\n",
        "        tr_loss += total_loss.item()\n",
        "        if device == \"cpu\":\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        else:\n",
        "            convert_models_to_fp32(model)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            clip.model.convert_weights(model)\n",
        "        pbar.set_description(f\"train batchCE: {total_loss.item()}\", refresh=True)\n",
        "    tr_loss /= step\n",
        "    \n",
        "    step = 0\n",
        "    te_loss = 0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        test_pbar = tqdm(test_dataloader, leave=False)\n",
        "        for batch in test_pbar:\n",
        "            step += 1\n",
        "            images, texts, _ = batch\n",
        "            images = images.to(device)\n",
        "            texts = clip.tokenize(texts).to(device)\n",
        "            logits_per_image, logits_per_text = model(images, texts)\n",
        "            ground_truth = torch.arange(BATCH_SIZE).to(device)\n",
        "\n",
        "            total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
        "            te_loss += total_loss.item()\n",
        "            test_pbar.set_description(f\"test batchCE: {total_loss.item()}\", refresh=True)\n",
        "        te_loss /= step\n",
        "        \n",
        "    preds = []\n",
        "    for image in x_test['img_path']:\n",
        "        image = preprocess(Image.open(image)).unsqueeze(0).to(device)\n",
        "        text = clip.tokenize(text_label).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            image_features = model.encode_image(image)\n",
        "            text_features = model.encode_text(text)\n",
        "\n",
        "            logits_per_image, logits_per_text = model(image, text)\n",
        "            probs = logits_per_image.softmax(dim=-1).cpu()\n",
        "            prob_idx = probs.argmax()\n",
        "            preds.append(prob_idx)\n",
        "            \n",
        "            \n",
        "    ans = x_test['label'].to_list()\n",
        "    print(metrics.accuracy_score(ans, preds))\n",
        "    f1_acc = metrics.f1_score(ans, preds, average = 'macro')\n",
        "    print(f1_acc)\n",
        "    f1_ls.append(f1_acc)\n",
        "            \n",
        "            \n",
        "\n",
        "    if best_f1 < f1_acc:\n",
        "        best_f1_acc = f1_acc\n",
        "        best_ep = epoch\n",
        "        torch.save(model.state_dict(), \"./best_model_change_val336gpuno2f.pt\")\n",
        "        \n",
        "    print(f\"epoch {epoch}, tr_loss {tr_loss}, te_loss {te_loss}\")\n",
        "torch.save(model.state_dict(), \"./lasttr224_model25.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h194zylLvwK1",
        "outputId": "f9dad8e8-6a7b-4d69-b74b-2514bfb8bdde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running epoch 0, best test loss 100000.0 after epoch -1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1205240174672489\n",
            "0.26613839223257507\n",
            "epoch 0, tr_loss 0.27306034525886913, te_loss 0.7308919270833333\n",
            "running epoch 1, best test loss 100000.0 after epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12838427947598252\n",
            "0.2662362653361232\n",
            "epoch 1, tr_loss 0.23845985287525615, te_loss 0.6375712076822917\n",
            "running epoch 2, best test loss 100000.0 after epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12838427947598252\n",
            "0.23022156909585045\n",
            "epoch 2, tr_loss 0.2053357421374712, te_loss 0.648297119140625\n",
            "running epoch 3, best test loss 100000.0 after epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12139737991266375\n",
            "0.23533435967178698\n",
            "epoch 3, tr_loss 0.174347173972208, te_loss 0.690667724609375\n",
            "running epoch 4, best test loss 100000.0 after epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1240174672489083\n",
            "0.26800396216004196\n",
            "epoch 4, tr_loss 0.14881710927994524, te_loss 0.6558848063151042\n",
            "running epoch 5, best test loss 100000.0 after epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.125764192139738\n",
            "0.24472606293017662\n",
            "epoch 5, tr_loss 0.13816375419741772, te_loss 0.7122517903645833\n",
            "running epoch 6, best test loss 100000.0 after epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11965065502183406\n",
            "0.25141041564083627\n",
            "epoch 6, tr_loss 0.14184682877337346, te_loss 0.73919677734375\n",
            "running epoch 7, best test loss 100000.0 after epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1222707423580786\n",
            "0.2603865106149806\n",
            "epoch 7, tr_loss 0.10039329528808594, te_loss 0.9364237467447917\n",
            "running epoch 8, best test loss 100000.0 after epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11965065502183406\n",
            "0.263726360761466\n",
            "epoch 8, tr_loss 0.10604459731305232, te_loss 0.7205546061197917\n",
            "running epoch 9, best test loss 100000.0 after epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-158-baca797117bd>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \"\"\"\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1989\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vjK9N0WIzoTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ugnpclIzBy2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l4VRIl72By5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x9xUel9zBy8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_list = glob.glob(base_dir + 'test/*/*')"
      ],
      "metadata": {
        "id": "1hn-El6GW2a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.DataFrame(columns=['img_path'])\n",
        "test['img_path'] = test_img_list"
      ],
      "metadata": {
        "id": "oBRbcawfW0CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fZPKelPlCgRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for image in test:\n",
        "    image = val_preprocess(Image.open(image)).unsqueeze(0).to(device)\n",
        "    text = clip.tokenize(text_label).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        image_features = model.encode_image(image)\n",
        "        text_features = model.encode_text(text)\n",
        "\n",
        "        logits_per_image, logits_per_text = model(image, text)\n",
        "        probs = logits_per_image.softmax(dim=-1).cpu()\n",
        "        prob_idx = probs.argmax().cpu().item()\n",
        "        preds.append(prob_idx)"
      ],
      "metadata": {
        "id": "MBHQ2qtDCgTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('/content/gdrive/MyDrive/open (2)/sample_submission.csv')"
      ],
      "metadata": {
        "id": "tLy1fc89By-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit['label'] = pd.Series(preds)"
      ],
      "metadata": {
        "id": "3wNrcSbqBzAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.loc[submit['label'] == 0, 'label'] = '가구수정'\n",
        "submit.loc[submit['label'] == 1, 'label'] = '걸레받이수정'\n",
        "submit.loc[submit['label'] == 2, 'label'] = '곰팡이'\n",
        "submit.loc[submit['label'] == 3, 'label'] = '꼬임'\n",
        "submit.loc[submit['label'] == 4, 'label'] = '녹오염'\n",
        "submit.loc[submit['label'] == 5, 'label'] = '들뜸'\n",
        "submit.loc[submit['label'] == 6, 'label'] = '면불량'\n",
        "submit.loc[submit['label'] == 7, 'label'] = '몰딩수정'\n",
        "submit.loc[submit['label'] == 8, 'label'] = '반점'\n",
        "submit.loc[submit['label'] == 9, 'label'] = '석고수정'\n",
        "submit.loc[submit['label'] == 10, 'label'] = '오염'\n",
        "submit.loc[submit['label'] == 11, 'label'] = '오타공'\n",
        "submit.loc[submit['label'] == 12, 'label'] = '울음'\n",
        "submit.loc[submit['label'] == 13, 'label'] = '이음부불량'\n",
        "submit.loc[submit['label'] == 14, 'label'] = '창틀,문틀수정'\n",
        "submit.loc[submit['label'] == 15, 'label'] = '터짐'\n",
        "submit.loc[submit['label'] == 16, 'label'] = '틈새과다'\n",
        "submit.loc[submit['label'] == 17, 'label'] = '피스'\n",
        "submit.loc[submit['label'] == 18, 'label'] = '훼손'"
      ],
      "metadata": {
        "id": "Z8KN-Ey6BzDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQaQf7CaCvZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PcaI_KH_CvcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LrCotw1ECveI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppPEVkXhCvgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ay9diUY3Cvia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SLSLOrhcCvkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-BalJn9DCvmp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}